
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="shortcut icon" href="../../assets/logo.svg">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.2.8">
    
    
      
        <title>Chapter 2: Setting up Batch Processing Orchestration with Composer and Airflow - Nunes Online</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.cb6bc1d0.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.39b8e14a.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
      
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#up-and-running-data-engineering-on-the-google-cloud-platform" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="Nunes Online" class="md-header-nav__button md-logo" aria-label="Nunes Online">
      
  <img src="../../assets/logo.svg" alt="logo">

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      <div class="md-header-nav__ellipsis">
        <div class="md-header-nav__topic">
          <span class="md-ellipsis">
            Nunes Online
          </span>
        </div>
        <div class="md-header-nav__topic">
          <span class="md-ellipsis">
            
              Chapter 2: Setting up Batch Processing Orchestration with Composer and Airflow
            
          </span>
        </div>
      </div>
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    




<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Nunes Online" class="md-nav__button md-logo" aria-label="Nunes Online">
      
  <img src="../../assets/logo.svg" alt="logo">

    </a>
    Nunes Online
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" >
      
      <label class="md-nav__link" for="nav-2">
        Articles
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Articles" data-md-level="1">
        <label class="md-nav__title" for="nav-2">
          <span class="md-nav__icon md-icon"></span>
          Articles
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../articles/i_was_a_lawyer/" class="md-nav__link">
        I was a lawyer. Now I'm a data engineer.
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../articles/learn_from_failure/" class="md-nav__link">
        How Great Teams Learn from Failure
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../articles/you_cant_build/" class="md-nav__link">
        You can’t build software without communication and teamwork
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../articles/trust_is_essential/" class="md-nav__link">
        Trust is Essential
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" >
      
      <label class="md-nav__link" for="nav-3">
        Book Reviews
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Book Reviews" data-md-level="1">
        <label class="md-nav__title" for="nav-3">
          <span class="md-nav__icon md-icon"></span>
          Book Reviews
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../book_reviews/clean_code/" class="md-nav__link">
        Clean Code by Robert C. Martin
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../book_reviews/rework/" class="md-nav__link">
        ReWork by Jason Fried and DHH
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
      
      <label class="md-nav__link" for="nav-4">
        Books
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Books" data-md-level="1">
        <label class="md-nav__title" for="nav-4">
          <span class="md-nav__icon md-icon"></span>
          Books
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
          
            
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1" type="checkbox" id="nav-4-1" checked>
      
      <label class="md-nav__link" for="nav-4-1">
        Up and Running: Data Engineering on the Google Cloud Platform
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Up and Running: Data Engineering on the Google Cloud Platform" data-md-level="2">
        <label class="md-nav__title" for="nav-4-1">
          <span class="md-nav__icon md-icon"></span>
          Up and Running: Data Engineering on the Google Cloud Platform
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_00_preface/" class="md-nav__link">
        Preface
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_01_gcp_account/" class="md-nav__link">
        Chapter 1: Setting up a GCP Account
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Chapter 2: Setting up Batch Processing Orchestration with Composer and Airflow
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Chapter 2: Setting up Batch Processing Orchestration with Composer and Airflow
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    Table of Contents
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_03_data_lake/" class="md-nav__link">
        Chapter 3: Building a Data Lake with Google Cloud Storage (GCS)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_04_data_warehouse/" class="md-nav__link">
        Chapter 4: Building a Data Warehouse with BigQuery
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_05_dags/" class="md-nav__link">
        Chapter 5: Setting up DAGs in Composer and Airflow
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_06_event_triggers/" class="md-nav__link">
        Chapter 6: Setting up Event-Triggered Pipelines with Cloud Functions
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_07_parallel_processing/" class="md-nav__link">
        Chapter 7: Parallel Processing with Dataproc and Spark
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_08_streaming/" class="md-nav__link">
        Chapter 8: Streaming Data with Pub/Sub
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_09_secrets/" class="md-nav__link">
        Chapter 9: Managing Credentials with Google Secret Manager
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_10_infrastructure_as_code/" class="md-nav__link">
        Chapter 10: Infrastructure as Code with Terraform
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_11_deployment_pipelines/" class="md-nav__link">
        Chapter 11: Deployment Pipelines with Cloud Build
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../ch_12_monitoring/" class="md-nav__link">
        Chapter 12: Monitoring and Alerting
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    Table of Contents
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="up-and-running-data-engineering-on-the-google-cloud-platform">Up and Running: Data Engineering on the Google Cloud Platform</h1>
<p>The completely free E-Book for setting up and running a Data Engineering stack on Google Cloud Platform.</p>
<p>NOTE: This book is currently incomplete. If you find errors or would like to fill in the gaps, read the <a href="https://github.com/Nunie123/data_engineering_on_gcp_book#user-content-contributions">Contributions section</a>.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<p><a href="https://github.com/Nunie123/data_engineering_on_gcp_book">Preface</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_01_gcp_account.md">Chapter 1: Setting up a GCP Account</a> <br>
<strong>Chapter 2: Setting up Batch Processing Orchestration with Composer and Airflow</strong> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_03_data_lake.md">Chapter 3: Building a Data Lake with Google Cloud Storage (GCS)</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_04_data_warehouse.md">Chapter 4: Building a Data Warehouse with BigQuery</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_05_dags.md">Chapter 5: Setting up DAGs in Composer and Airflow</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_06_event_triggers.md">Chapter 6: Setting up Event-Triggered Pipelines with Cloud Functions</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_07_parallel_processing.md">Chapter 7: Parallel Processing with Dataproc and Spark</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_08_streaming.md">Chapter 8: Streaming Data with Pub/Sub</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_09_secrets.md">Chapter 9: Managing Credentials with Google Secret Manager</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_10_infrastructure_as_code.md">Chapter 10: Infrastructure as Code with Terraform</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_11_deployment_pipelines.md">Chapter 11: Deployment Pipelines with Cloud Build</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_12_monitoring.md">Chapter 12: Monitoring and Alerting</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_13_up_and_running.md">Chapter 13: Up and Running - Building a Complete Data Engineering Infrastructure</a> <br>
<a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/appendix_a_example_code/README.md">Appendix A: Example Code Repository</a></p>
<hr />
<h1 id="chapter-2-setting-up-batch-processing-orchestration-with-composer-and-airflow"><a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_02_orchestration.md">Chapter 2</a>: Setting up Batch Processing Orchestration with Composer and Airflow</h1>
<h2 id="apache-airflow-overview">Apache Airflow Overview</h2>
<p>Apache Airflow is a widely used open-source tool for orchestrating data pipelines written in Python. Airflow has a lot of great features, but two things it's particularly handy for is: 
1. Allowing you to schedule data processing jobs.
2. Organize dependencies for your data processing job.</p>
<p>Scheduling can be a trickier problem than it seems. What happens if a job isn't finished before it is scheduled to run again? What happens when the scheduling application is down at the time a job is scheduled. What if you realize you have a bug in your data processing code, and you need to reprocess all of your data for your scheduled runs for the last month? Airflow's scheduling has answers and configuration options for these sorts of scheduling problems. It's worth noting that GCP has a dedicated scheduling service, called <a href="https://cloud.google.com/scheduler">Cloud Scheduler</a>, but Airflow works better for our needs.</p>
<p>Managing processing dependencies is a big part of creating a robust data pipeline (this is distinct from environment dependencies, such as whether Python is installed on your machine). </p>
<p>If we're moving data from the Google Analytics API to a BigQuery table we know that we better download that data first before we try to load it into BigQuery. One way to manage this dependency is within our code, and every time we want this data updated we run our script. But suppose it takes an hour to download the data, and 5 minutes to upload it to BigQuery. If the script fails during the upload then you may be stuck running the whole script again, waiting another hour to download data that's already on your local disk. Alternatively, you could go about developing custom error handling for each of your pipelines that allows it to be restarted in pieces. If you've got a lot of pipelines, that means a lot of code to write and maintain.</p>
<p>Airflow addresses this problem through the use of "Tasks", which are chunks of work that Airflow manages. These Tasks are organized into a Directed Acyclic Graph (DAG), which is a group of Tasks with dependencies defined between these Tasks. So you might have a DAG called "update_google_analytics_table" that has two Tasks: "download_data_from_google_analytics" and "upload_data_to_bq". We can tell airflow that "download_data_from_google_analytics" must complete successfully before "upload_data_to_bq" is run, and if either Task fails Airflow is to retry running the Task. After a designated number of retries, if the Task still has not succeeded it will mark itself as failed (in <a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_13_up_and_running.md">Chapter 13</a> we'll discuss setting up alerts for these failures).</p>
<p>Another nice feature of Airflow is that it has a browser-based GUI that is useful for managing and monitoring your DAGs.<br>
<img alt="Airflow Screenshot" src="../images/airflow_dag_sample_1.png" /></p>
<p>Whole <a href="https://www.manning.com/books/data-pipelines-with-apache-airflow">books</a> have been written about Apache Airflow, and we've only scratched the surface. But this chapter is just focused on configuring Airflow to run, we'll revisit Airflow in <a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_05_dags.md">Chapter 5</a>, where we'll discuss programming DAGs to run your data pipelines.</p>
<h2 id="google-cloud-composer-overview">Google Cloud Composer Overview</h2>
<p>Cloud Composer is Google's fully managed Airflow service. So rather than renting compute instances and installing Airflow yourself, Composer manages the compute instances for you under the hood. </p>
<p>While offloading some of DevOps work to GCP is nice, it does provide a complication: Because GCP is a managed service, you are not able to run it locally. So your options are to create a composer instance on GCP for every developer, or set up a dockerized Airflow instance to run locally for development.</p>
<p>The rest of this chapter will be dedicated to setting up your own Cloud Composer instance on GCP.</p>
<h2 id="setting-up-cloud-composer-on-gcp">Setting up Cloud Composer on GCP</h2>
<p>Apache Airflow, whether installed yourself or managed by GCP, requires a collection of infrastructure pieces that coordinate to make the application work. GCP calls an Airflow instance an "Environment" because what you are launching is the environment for all these pieces to work together. Cloud Composer uses the following GCP services to run: Cloud SQL, App Engine, Cloud Storage, Kubernetes Engine, Cloud Logging, Cloud Monitoring, and Pub/Sub. Fortunately GCP handles all that infrastructure for us.</p>
<p>It's also important to be aware that unlike some other services by GCP, Composer does not auto-scale. You are required to designate the number and size of the machines you want to use, with more compute power assigned meaning an increased bill from GCP. If you need to change your assigned compute power you must do so manually.</p>
<h3 id="creating-the-composer-instance">Creating the Composer Instance</h3>
<p>In <a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_01_gcp_account.md">Chapter 1</a>I discussed installing the GCP command line tools. You'll need them for this section.</p>
<p>You're first step is to enable Cloud Composer, which you can do <a href="https://console.cloud.google.com/flows/enableapi?apiid=composer.googleapis.com">here</a>. Select your Project from the drop-down and click "Continue". You'll be taken to a page prompting you to set up your credentials. GCP is reminding you that you should set up a Service Account that will allow you to access the Composer API that you just enabled. We already set up our Service Account in Chapter 1, but now we can grant the Service Account permission to set up a Composer Environment:</p>
<pre><code class="language-bash">&gt; gcloud projects add-iam-policy-binding 'de-book-dev' \
    --member='serviceAccount:composer-dev@de-book-dev.iam.gserviceaccount.com' \
    --role='roles/composer.worker'
</code></pre>
<p>As stated above, a Composer "Environment" is equivalent to a managed Airflow instance. You create an Environment through the <a href="https://console.cloud.google.com/composer/environments/create">console</a> and through the <code>gcloud</code> utility. In <a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_11_deployment_pipelines.md">Chapter 11: Deployment Pipelines with Cloud Build</a> I will go over managing your GCP infrastructure with Terraform, including managing Composer Environments.</p>
<p>We can create a Composer Environment with the following command (WARNING: it can take up to a half hour to create the Environment):</p>
<pre><code class="language-bash">&gt; gcloud composer environments create my-dev-environment \
    --location us-central1 \
    --zone us-central1-f \
    --machine-type n1-standard-1 \
    --image-version composer-1.12.2-airflow-1.10.10 \
    --python-version 3 \
    --node-count 3 \
    --service-account composer-dev@de-book-dev.iam.gserviceaccount.com 
</code></pre>
<p>I've specified a few common options, but there are many more options that you can read about <a href="https://cloud.google.com/composer/docs/how-to/managing/creating?authuser=1#gcloud">here</a>.</p>
<p>To verify your Environment is running you can execute:</p>
<pre><code class="language-bash">&gt; gcloud composer environments list --locations us-central1
┌────────────────────┬─────────────┬─────────┬──────────────────────────┐
│        NAME        │   LOCATION  │  STATE  │       CREATE_TIME        │
├────────────────────┼─────────────┼─────────┼──────────────────────────┤
│ my-dev-environment │ us-central1 │ RUNNING │ 2020-10-16T04:04:19.264Z │
└────────────────────┴─────────────┴─────────┴──────────────────────────┘
&gt; gcloud composer environments describe my-dev-environment --location us-central1
</code></pre>
<h3 id="testing-a-dag">Testing a DAG</h3>
<p>The point of the Airflow instance is to orchestrate your DAGs, which is how you'll organize your batch data processing. I'll be talking a lot more about how to make DAGs in <a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_05_dags.md">Chapter 5</a> (after we talk about GCS and BigQuery), but I'll go over a quick example here.</p>
<p>A DAG is defined in a Python file that Airflow monitors and executes when scheduled. We'll create a DAG that has two tasks: one task will download a list of (mock) products and the other task will print a message indicating the task completed. In <a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_11_deployment_pipelines.md">Chapter 11: Deployment Pipelines with Cloud Build</a> I will discuss how to automate the deployment of these files to GCP, where they will run, but for now we can do that manually. So let's make our Python file:</p>
<pre><code class="language-python"># my_first_dag.py

import requests
import datetime

from airflow import DAG
from airflow.operators.bash_operator import BashOperator
from airflow.operators.python_operator import PythonOperator

default_args = {
    'owner': 'DE Book',
    'depends_on_past': False,
    'email': [''],
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': datetime.timedelta(seconds=30),
    'start_date': datetime.datetime(2020, 10, 17),
}

dag = DAG(
    'my_first_dag',
    schedule_interval=&quot;6 * * * *&quot;,   # run every day at 6am UTC
    max_active_runs=1,
    catchup=False,
    default_args=default_args
)


# A function to download product data from a web API.
def get_product_data() -&gt; str:
    url = 'https://gorest.co.in/public-api/products'
    result = requests.get(url)
    data = result.json()
    products = data['data']
    return f'We downloaded {len(products)} products!'


# A task to download product data from a web API. 
t_get_product_data = PythonOperator(
    task_id='get_product_data',
    python_callable=get_product_data,
    dag=dag
)


# A task to print that the product data has been downloaded.
t_print_message = BashOperator(
    task_id='print_message',
    bash_command='echo &quot;Product data has been downloaded. Congrats on your first DAG!!!!!!!&quot;',
    dag=dag
)


# Setting the first task as a dependency for the second task.
t_print_message.set_upstream(t_get_product_data)


# In a more realistic DAG we would be saving this data to GCS, then updating BigQuery. 
# We'll dive deeper into building DAGs in [Chapter 5](https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_05_dags.md).
</code></pre>
<p>Now we need to put our DAG file where our Composer Environment can find it. GCP handles this by sticking all of the DAGs in a GCS bucket. We can find the bucket by running:</p>
<pre><code class="language-bash">&gt; gcloud composer environments describe my-dev-environment \
    --location us-central1 \
    --format=&quot;get(config.dagGcsPrefix)&quot;
gs://us-central1-my-dev-environm-63db6d2e-bucket/dags
</code></pre>
<p>You can access the bucket with your DAGs just like any other bucket (we talk more about GCS in <a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_03_data_lake.md">Chapter 3</a> ), but we don't actually need to access the bucket directly to add our DAG. Instead we can use the command:</p>
<pre><code class="language-bash">&gt; gcloud composer environments storage dags import \
    --environment my-dev-environment \
    --location us-central1 \
    --source my_first_dag.py
</code></pre>
<p>Now lets view the Airflow web interface so we can see our DAG running. We can see the address by running:</p>
<pre><code class="language-bash">&gt; gcloud composer environments describe my-dev-environment \
    --location us-central1 \
    --format=&quot;get(config.airflowUri)&quot;
</code></pre>
<p>Copy that address to your browser, and authenticate if required. We'll talk more about the Airflow web interface in <a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_05_dags.md">Chapter 5</a>. For now lets click on "my_first_dag".</p>
<p><img alt="Airflow web interface" src="../images/airflow_web_ui_1.png" /></p>
<p>From here we can see that our tasks completed successfully.</p>
<h2 id="cleaning-up">Cleaning Up</h2>
<p>GCP charges us for using the services we set up in this chapter. We will be using this Composer Environment again in <a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_05_dags.md">Chapter 5</a>, so if you don't feel like setting it up again you can keep it running. Just be aware of your costs for <a href="https://cloud.google.com/composer/pricing">Composer</a> and <a href="https://cloud.google.com/storage/pricing">GCS</a>. When we set up our Composer Environment GCP also set up resources in GCS for us, which is convenient for setting Airflow up. We just have to remember we have more to shut down than Composer when we are cleaning up.</p>
<p>We can delete the Composer Environment by running:</p>
<pre><code class="language-bash">&gt; gcloud composer environments delete my-dev-environment --location us-central1
</code></pre>
<p>I already provided the command for finding the related bucket above. You can also find it by looking through all your buckets for the one named after your Composer Environment:</p>
<pre><code class="language-bash">&gt; gsutil list
gs://us-central1-my-dev-environm-63db6d2e-bucket/
</code></pre>
<p>Now we can delete the bucket with:</p>
<pre><code class="language-bash">&gt; gsutil rm -r gs://us-central1-my-dev-environm-63db6d2e-bucket/
</code></pre>
<hr />
<p>Next Chapter: <a href="https://github.com/Nunie123/data_engineering_on_gcp_book/blob/master/ch_03_data_lake.md">Chapter 3: Building a Data Lake with Google Cloud Storage (GCS)</a></p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../ch_01_gcp_account/" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Chapter 1: Setting up a GCP Account
              </div>
            </div>
          </a>
        
        
          <a href="../ch_03_data_lake/" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Chapter 3: Building a Data Lake with Google Cloud Storage (GCS)
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.18f0862e.min.js"></script>
      <script src="../../assets/javascripts/bundle.994580cf.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: ['navigation.instant'],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.9c0e82ba.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>